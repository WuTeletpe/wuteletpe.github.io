![](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1570850666879.png)

### 架构

0.web server app
1.web server framework
2.http server
3.tcp server



- nginx : http server
- gunicorn: http server 只能运行在Unix系统上
- wsgi: 包装出来一个app。

#### 详细解释wsgi

WSGI规范的目的就是解耦Web Server 和Web Application。

一个完整的WSGI协议包括server 和appliction 两部分。server的作用是接受客户端传来的请求，转发给application， 然后把application返回的response发给客户端。

gunicorn， uwsgi就是实现了WSGI server协议的web server。 而我们常用的Django，Flask等等就是实现了WSGI application协议的 web framework。



#### 为什么有了gunicorn还要用nginx?

data -> nginx -> gunicorn -> wsgi -> app 客观上来说多了nginx一层的确会增加时间

但有以下好处：

1. 反向代理
    gunicorn 2000 这是第一个服务
    gunicorn 2002 这是第二个服务，两个服务共同构成后端的逻辑
    nginx 80
    
2. 负载均衡（nginx也可以做负载均衡，但通常大家不一定用他做）
   
    去访问google.com 如何部署大量的google服务器，让每个的压力都不大
    
    比如用开源组件haproxy 
    
3. 静态文件托管

    常规做法：你上传文件->到服务器->服务器保存到本地的一个位置

    你访问->服务器接到请求->从本地把文件拉起来send给你

    send_by_directory 每次都send性能很不好
    配置了一个rule，把文件保存在nginx的缓存，不会走到app这一层

4. 缓冲
    traffic busy 这时你的 gunicorn 已经处理不了

    所以我们不应该把请求转发给 gunicorn 了，

    缓存一下这些请求，等 gunicorn 不忙再交给它

    缓冲负载

以上，那加了nginx会快吗？当你只有一个app，一个机器，多一层就不会快

但如果你是多机并发处理，用负载均衡会让你快一点



### 其他架构知识

大部分架构的问题都是分布式下的

1. vagrant
    openstack
    docker
    
2. 架构

web application republications 把所有业务打成一个包，往多台机器的多个端口上部署，用Nginx转发
SOA 面向服务编程 把一些业务拆出来，把重的那部分复制很多份
   micro service 把app中每一个蓝图封装成一个进程，变成了一个个独立的服务

   但微服务带来了如下问题

    2.1 语言的异构 

   不同服务进程间通信是用的tcp，传的东西可能是json,xml等等，都跟语言无关。

   那么我每个服务可以用任何语言来写。

   重IO的如数据库操作不占用cpu，可以用py，

   重计算的如推荐算法占用cpu，可以用c，c++，go

   这样，后端的语言走向了异构

    2.2 微服务提供的api回应的是数据如json而不是页面，

   即api全是数据接口， 这样导致前端会有两种模式

   1. 全在前端渲染，前端拿到数据，操作DOM
   
   2. 前后端渲染混合，比如电商平台，页面大量是静态化的，后端很多静态化
   
      前端有一些交互操作特别多的（如聊天）是前端渲染

   以前的调模板方式其实是后端渲染出来的，但现在微服务背景下不会是纯后端渲染了

    2.3 自动弹性，容器，虚拟化，LaaS PaaS

   一个服务是一个进程，你可以想象成一个json api，可以被打包为一个容器里的服务

   

3. 分布式

  前提：你现在是多台机器，做负载均衡了。

  CAP猜想->CAP定理
  C 一致性 两个数据库里的数据总是一致的
  A 可用性 读操作和写操作都能在一段时间内得到返回值 网页不会卡住
  P **网络分区的可容忍性** 一定要保证（因为谁的机器都可能会挂） 你有很多机器。网络中的一些机器瘫痪了，另一些还能运行下去
   3.1. 小米 PC 牺牲可用性：保证数据是正确的，因为我卖的手机就只有那么多
   3.2. 电商 做秒杀 （只是一部分电商这么做,另一部分还是PC）PA：只有一个货但发出去3个（没关系，补货就行），但你马上就可以看到你抢到了（可用性好）

4. 后端现有架构图

    ![](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1570858898716.png)

    ![1570859079119](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1570859079119.png)

5. 什么是jsonrpc ? xmlrpc? soap ? restful api? --cheap knowledge

  都是网络客户端与服务端通信的方式，现在的主流是jsonrpc和restful api

  - jsonrpc 是用http协议传了一个 json数据 有返回值，返回格式是：result['result']

  - 萧大课上实现的rpc是基于tcp的，直接用socket实现的rpc

  - xmlrpc 也是用http协议传了一个xml数据

  - soap 也可以理解成一种rpc（其实是远程调用的方法）
    
  - restful api 这个不是rpc，而是跟jsonrpc并列的另一种方式。 **http method做增删改查**，但很多操作做不了，灵活性不足

6. 性能的代价
    jsonrpc 的缺点
   6.1 overhead  因为建立在http上，而封装和抽象是有代价的。从tcp到http本身就加了http头，一堆header，body只有一点

  这个代价直接导致优化服务器性能有可能都不如这堆header在网络中传输的时间

   6.2 单工（由于是http，所以总是一应一答）本来socket是能双工的(读和写同时做），这里降低了性能。
   但带来的好处

  1. 简单：可以很简单的封装出rpc来
  2. 不会rpc乱序：tcp不能保证操作1比操作2先做。http可以

  好处是否值得这样的代价，得看场景，比如聊天室场景下就还是该tcp（我需要响应快，高实时）

7. websocket：我在js中创建了一个socket对象（就像是萧大课上的python rpc客户端），实现了tcp传输。库：socket-io

   下图是客户端的websocket用法，当你要写服务器端的时候，可能需要装对应语言的socket库

   ## 客户端的 API

   ![1570860676146](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1570860676146.png)

   ![1570861073181](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1570861073181.png)

8. 聊天室

9. 聊天，room，对于room广播

10. 加入房间，退出房间

11. jquery

12. socket.io

13. socket.io server

14. tcp socket io session



### 性能

1. web性能 选择的并不是性能最高的语言 节省服务器
2. web性能组成
    吴多益 打开浏览器，点击百度，搜了一个query，返回了结果
    那么发生了什么事情？

    1. 发了一个request
    2. 到达了负载均衡 比如 haproxy
    3. 到达了nginx   到这儿为止是运维关心
    4. 到达了web server gunicorn web框架开发者 request解析，路由转发
    5. 发送了你的web server app ： **后端开发者要让application层面跑得快**
    6. web server app做了各种事情，返回了response

    以上是服务器处理的时间
    
7. 动态产生一堆页面，客户端渲染  前端工程师
   
3. 性能本身以后评测标准
    1. 说明硬件，某种网络设备
    2. 性能测试的时候切忌方法
        1. benchmark程序，已经跑满，而你的app没有跑满
        2. 多个客户端，每个客户端可能有几个链接
    3. 指标 每秒处理多少个请求

    框架作者喜欢测试hello world ？因为hello world本身解析请求，路由

4. ab这个工具 apache benchmark


### 测试case

1. 需要模拟有性能瓶颈的情况，topic all做一下sleep
2. 做优化的方法 cache
    a. 有一个操作很耗时，那么我们应该结果cache，下一次就很快了
    b. cache肯定不是永久有效的，topic来说，你每次改的时候都会失效
    c. 在每次失效的时候更新cache
1. 我们用内存直接cache
2. 我们不用内存，用reids
    以前我们做cache的时候，memcached
    现在redis
1. 发现问题所在，profiling
2. 根据这个问题去做bench
3. 做cache
8. 注意安全 



### 虚拟化技术

vagrant

DevOps 一种理念

做op 将代码部署到服务器上

由于会有开发环境和生产环境不一样的尴尬

所以出现了虚拟化技术

我开发其实是在一个虚拟机上，上线的时候上线的也是一个虚拟机

达到了--开发和部署环境是一样的

虚拟化技术

1. openstack 基于虚拟机技术，慢。能让你把服务部署到虚拟机上。
2. docker 基于容器技术，快。（一个不懂的小坑，容器是抢占式的，很难分析清你的瓶颈是在哪）
3. vagrant 不是用于线上的，开发测试用的。让你配一遍以后，其他开发者也能用你的环境